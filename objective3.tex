
\msection{Attentional Filtering (Objective 3) }
\label{sec:aim3}

More information is available to our senses than the human brain can
handle. As a result, we process only a subset of this information and
this determines what enters into conscious
awareness~\citep{Most:2005}, what dimensions we learn
over~\citep{Turk-Browne:2005}, and what we store in
memory~\citep{Aly:2016}. The principles and mechanisms governing the
selection of sensory information are referred to as the study of
\textit{attention}. An analogous problem, known as the curse of
dimensionality, arises in statistical machine learning for
high-dimensional problems. As with human attention, reducing the
dimensionality of data can make learning tractable. Here we will
explore whether our understanding of attention in cognitive
neuroscience can inform assumptions made in machine learning, and how
techniques for recovering lower-dimensional representations in machine
learning can be used to reconstruct fluctuations in human attention
from brain imaging data.

\biobackground{} Attention in the human brain is sometimes controlled
reflexively by the salience of stimuli that we perceive, in terms of
contrast, motion, and other sensory features~\citep{Itti:2000}. This
stimulus-driven or bottom-up form of attention explains how our focus
is automatically drawn to an approaching siren or to a smartphone
lighting up with a text message. It can be contrasted with
goal-directed or top-down attention, whereby we volitionally shift our
focus based on which stimuli are relevant for our current behavioral
goals~\citep{Yantis:2000}. For both stimulus-driven and goal-directed
forms, attention is directed at external stimuli, enhancing evoked
activity in brain areas that code for their locations and
features~\citep{Kastner:2000} and increasing functional connectivitity
between these areas~\citep{Turk-Browne:2013}. This modulation occurs
as a result of control structures in frontoparietal cortex that send
biasing signals to visual cortex~\citep{Noudoost:2010}. In addition,
attention can be directed toward internal representations, such as
thoughts, memories, and responses, and this is mediated by similar
control structures in the brain~\citep{Chun:2011}. This internal
attention, as well as goal-directed external attention, share the
fascinating property that are not determined by the appearance of the
world. Rather, they reflect computations in the mind and allow each
individual to process the same sensory input in different ways. The
challenge for understanding these forms of attentional filtering is
being able to characterize the inner mental life of a person, even in
cases where they do not or cannot disclose their focus.

Several related methods have been developed in recent years to infer
mental experience from brain data, including
colors~\citep{Brouwer:2009}, scenes~\citep{Naselaris:2009},
faces~\citep{Cowen:2014}, and locations~\citep{Sprague:2016}. The
basic form of such reconstruction or inverted encoding modeling
involves: (1) specifying a basis set of channels that tile the
dimension to be reconstructed; (2) predicting the activation of each
channel given the position of each stimulus used in the experiment on
that dimension; (3) for a training set of fMRI data, modeling the
observed neural responses to these stimuli in each voxel as a weighted
sum of the predicted channel activations; (4) this results in an
estimated weight matrix of the extent to which each channel is encoded
in each voxel, from which a tuning curve for each voxel can be
computed as a weighted sum of the basis set; (5) by inverting this
estimated weight matrix, test fMRI data with the pattern of neural
responses across voxels for an unknown stimulus can be used to
estimate channel activation; (6) the weighted sum of these estimated
channel activations by the basis set provides a continuous readout of
the information present in the brain along the dimension of interest,
which can be used as is or for decoding by finding the stimulus whose
predicted channel activations (from step 2) are most correlated.

Although these methods are cutting-edge and powerful in cognitive
neuroscience, and they come tantalizingly close to ''mind reading'',
they are currently limited in two ways. First, they require an
assumption (for training and decoding) that the brain veridically
represents the properties of the stimulus used as labels (e.g., known
visual or semantic features). To the extent that attention filters the
stimulus in some way, this changes the ground truth about which
features the brain should be representing, inherently limiting
reconstruction accuracy. Second, these methods are generally applied
to stimuli with one or a small number of potential dimensions that are
used for reconstruction. However, naturalistic stimuli are
high-dimensional and dynamic, increasing the likelihood that people
are shifting their attention between dimensions. We will thus extend
these approaches by attempting to reconstruct from brain activity not
only what stimulus information is present in each dimension but also
to which dimension(s) attention is directed. We will deploy methods
from machine learning that can uncover lower-dimensional traces
through high-dimensional data to infer how attention is filtering the
stimulus, even when the attentional focus during the training data is
unknown (e.g., because it was not manipulated or measured). Our
overall goal is to improve decoding accuracy by reconstructing what is
represented in the mind rather than what is presented to the eyes.

%COULD BE USEFUL IN THE PROJECT DESCRIPTION BELOW Consider the task of reconstructing a person's subjective experience of a movie from their brain data. Existing inverse modeling methods attempt to reproduce the pixels of the photos or movie frames being shown to the person, but if the human brain only represents a subset of this information these models have an inherent performance ceiling. Pixels are not ground truth for the brain, but the problem is that there is no principled way to figure out the internal ``ground truth'' (which can also vary from moment to moment). A useful public dataset for examining this is 17 subjects who watched a 90 minute episode of Sherlock while being scanned with fMRI. We have a frame-by-frame annotation of several dimensions of the movie, and so could try to reconstruct which of these dimensions are present in the brain data and how this attentional trace changes dynamically over time.

\statbackground{} High-dimensional problems suffer from the curse of
dimensionality. This has a precise mathematical characterization in
standard models of statistical machine learning. The curse of
dimensionality has two components, one statistical, the other
computational. The statistical issue stems from the observation that
in high dimensions, any local ball will contain very few data
points. The computational curse is implied by the fact that searching
over a sufficiently large space of models is often
intractable. ``Beating'' the curse of dimensionality involves making
assumptions about the structure of the learning problem. We will study
mathematical formulations of attention as one approach to making
assumptions for which learning is tractable in principle.
In an attention-based model, the object of study is a
lower-dimensional trace or curve through the high-dimensional input
space. 

In the deep learning literature, attention-based models were first
developed in the setting of machine translation, using
sequence-to-sequence algorithms based on recurrent neural networks
(RNNs) \citep{bahdanau2014}. The attention mechanism is a type of alignment model,
which is a key component of statistical translation methods
\citep{Brown1993}. Attention has been applied to the problem of generating image
descriptions by \cite{showtell}.

Recall from Section~\ref{sec:aim1} that an exponential family
embedding model uses a latent representation of the input and output
variables. Consider the case of high dimensional density estimation,
where the goal is to estimate a density $p(x)$ for $x\in\reals^d$.
A latent variable embedding model takes the form
$$ p(x) = \int p(z) \exp(\rho(x)^T \alpha(z) - \Psi_{\rho,\alpha}) \, dz$$
where $z\in \reals^m$ is a latent Gaussian vector,
$\rho:\reals^d \to \reals^K$ is an embedding of the input space,
and $\alpha: \reals^m \to\reals^K$ is an embedding of the latent
Gaussian, and $\Psi_{\rho,\alpha}$ is a normalizing constant.
We will investigate attention-based versions of embedding
models. Many possibilities exist for doing so. For instance, consider a parameterized curve $t\mapsto (Z_t, S_t)$
where $Z_t$ is a Gaussian vector and $S_t \subset \{1,\ldots, d\}$
is a subset of the input variables. Define the inner product 
$\langle x, z\rangle_{\rho,\alpha}
= \int_{0}^1 \rho\left(x_{S(t)}\right)^T \alpha(Z_t) dt,$
and the corresponding embedding model
$ p(x) = \int p(z) \exp\left(\langle x, z\rangle_{\rho,\alpha} - \Psi_{\rho,\alpha}\right) dz.$
In another version, consider a graph over $\{1,\ldots, d\}$ with edge
set $E$, and define the inner product
$\langle x, z\rangle_{\rho,\alpha}
= \sum_{(j,k)\in E} \rho(x_j, x_k)^T \alpha(Z_j, Z_k)$
where $Z$ is now a vector-valued Gaussian random field, 
and the model can be viewed as a nonparametric graphical model
\citep{hl18}.

These are thought of as attention-based models as the ``energy''
$\langle x, z\rangle_{\rho,\alpha}$ is localized to subsets of the
sample space. Discriminative or regression-based versions of these
models are defined similarly. The project will develop variational
inference algorithms for this family of models. When the mapping 
$\alpha(z)$ is defined in terms of, for instance, a feed-forward
neural network, this becomes an instance of a variational auto-encoder
\citep{kingma13}.


\vskip20pt

\project{Algorithms using variational inference}

\project{Learning complexity under attention}

\project{Applications to fMRI movie data}

\project{Experiments with fMRI to test attention models}



 
