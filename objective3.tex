
\msection{Attentional Filtering (Objective 3) }
\label{sec:aim3}

More information is available to our senses than the human brain can
handle. As a result, we process only a subset of this information and
this determines what enters into conscious
awareness~\citep{Most:2005}, what dimensions we learn
over~\citep{Turk-Browne:2005}, and what we store in
memory~\citep{Aly:2016}. The principles and mechanisms governing the
selection of sensory information are referred to as the study of
\textit{attention}. An analogous problem, known as the curse of
dimensionality, arises in statistical machine learning for
high-dimensional problems. As with human attention, reducing the
dimensionality of data can make learning tractable. Here we will
explore whether our understanding of attention in cognitive
neuroscience can inform assumptions made in machine learning, and how
techniques for recovering lower-dimensional representations in machine
learning can be used to reconstruct fluctuations in human attention
from brain imaging data.

\biobackground{} Attention in the human brain is sometimes controlled
reflexively by the salience of stimuli that we perceive, in terms of
contrast, motion, and other sensory features~\citep{Itti:2000}. Such
stimulus-driven or bottom-up form of attention explains how our focus
is automatically drawn to an approaching siren or to a smartphone
lighting up with a text message. This can be contrasted with
goal-directed or top-down attention, whereby we volitionally shift our
focus based on which stimuli are relevant for our current behavioral
goals~\citep{Yantis:2000}. In both of these cases, attention is
directed at external stimuli and enhances evoked responses in brain
areas that code for their location and features~\citep{Kastner:2000}
and increases functional connectivitity between these
areas~\citep{Turk-Browne:2013}. This modulation occurs as a result of
control structures in frontoparietal cortex that send biasing signals
to visual cortex~\citep{Noudoost:2010}. In addition, attention can be
directed toward internal representations, such as thoughts, memories,
and responses, and this is mediated by similar control structures in
the brain~\citep{Chun:2011}. This internal attention and goal-directed
external attention share the fascinating property that are not
determined by the appearance of the world. Rather, they reflect
computations in mind and allow each individual to process the same
sensory input in different ways. The challenge for understanding these
forms of attentional filtering is being able to characterize the inner
mental life of a person, even in cases where they do not disclose
their focus.

NTB WORKING HERE AND BELOW IN OBJECTIVE 3
Consider the task of reconstructing a person's
subjective experience of a movie from their brain data. Existing
inverse modeling methods attempt to reproduce the pixels of the photos
or movie frames being shown to the person, but if the human brain only
represents a subset of this information these models have an inherent
performance ceiling. Pixels are not ground truth for the brain, but
the problem is that there is no principled way to figure out the
internal ``ground truth''  (which can also vary from moment to moment). A useful public dataset for examining this is 17 subjects who watched a 90 minute episode of Sherlock while being scanned with fMRI. We have a frame-by-frame annotation of several dimensions of the movie, and so could try to reconstruct which of these dimensions are present in the brain data and how this attentional trace changes dynamically over time.

\statbackground{} High-dimensional problems suffer from the curse of
dimensionality. This has a precise mathematical characterization in
standard models of statistical machine learning. The curse of
dimensionality has two components, one statistical, the other
computational. The statistical issue stems from the observation that
in high dimensions, any local ball will contain very few data
points. The computational curse is implied by the fact that searching
over a sufficiently large space of models is often
intractable. ``Beating'' the curse of dimensionality involves making
assumptions about the structure of the learning problem. We will study
mathematical formulations of attention as one approach to making
assumptions for which learning is tractable in principle.
In an attention-based model, the object of study is a
lower-dimensional trace or curve through the high-dimensional input
space. 

In the deep learning literature, attention-based models were first
developed in the setting of machine translation, using
sequence-to-sequence algorithms based on recurrent neural networks
(RNNs) \citep{bahdanau2014}. The attention mechanism is a type of alignment model,
which is a key component of statistical translation methods
\citep{Brown1993}. Attention has been applied to the problem of generating image
descriptions by \cite{showtell}.

Recall from Section~\ref{sec:aim1} that an exponential family
embedding model uses a latent representation of the input and output
variables. Consider the case of high dimensional density estimation,
where the goal is to estimate a density $p(x)$ for $x\in\reals^d$.
A latent variable embedding model takes the form
$$ p(x) = \int p(z) \exp(\rho(x)^T \alpha(z) - \Psi_{\rho,\alpha}) \, dz$$
where $z\in \reals^m$ is a latent Gaussian vector,
$\rho:\reals^d \to \reals^K$ is an embedding of the input space,
and $\alpha: \reals^m \to\reals^K$ is an embedding of the latent
Gaussian, and $\Psi_{\rho,\alpha}$ is a normalizing constant.
We will investigate attention-based versions of embedding
models. Many possibilities exist for doing so. For instance, consider a parameterized curve $t\mapsto (Z_t, S_t)$
where $Z_t$ is a Gaussian vector and $S_t \subset \{1,\ldots, d\}$
is a subset of the input variables. Define the inner product 
$\langle x, z\rangle_{\rho,\alpha}
= \int_{0}^1 \rho\left(x_{S(t)}\right)^T \alpha(Z_t) dt,$
and the corresponding embedding model
$ p(x) = \int p(z) \exp\left(\langle x, z\rangle_{\rho,\alpha} - \Psi_{\rho,\alpha}\right) dz.$
In another version, consider a graph over $\{1,\ldots, d\}$ with edge
set $E$, and define the inner product
$\langle x, z\rangle_{\rho,\alpha}
= \sum_{(j,k)\in E} \rho(x_j, x_k)^T \alpha(Z_j, Z_k)$
where $Z$ is now a vector-valued Gaussian random field, 
and the model can be viewed as a nonparametric graphical model
\citep{hl18}.

These are thought of as attention-based models as the ``energy''
$\langle x, z\rangle_{\rho,\alpha}$ is localized to subsets of the
sample space. Discriminative or regression-based versions of these
models are defined similarly. The project will develop variational
inference algorithms for this family of models. When the mapping 
$\alpha(z)$ is defined in terms of, for instance, a feed-forward
neural network, this becomes an instance of a variational auto-encoder
\citep{kingma13}.


\vskip20pt

\project{Algorithms using variational inference}

\project{Learning complexity under attention}

\project{Applications to fMRI movie data}

\project{Experiments with fMRI to test attention models}



 
