
@article{Chun:2011,
	title = {A taxonomy of external and internal attention},
	volume = {62},
	url = {http://www.annualreviews.org/doi/abs/10.1146/annurev.psych.093008.100427},
	doi = {10.1146/annurev.psych.093008.100427},
	abstract = {Attention is a core property of all perceptual and cognitive operations. Given limited capacity to process competing options, attentional mechanisms select, modulate, and sustain focus on information most relevant for behavior. A significant problem, however, is that attention is so ubiquitous that it is unwieldy to study. We propose a taxonomy based on the types of information that attention operates over—the targets of attention. At the broadest level, the taxonomy distinguishes between external attention and internal attention. External attention refers to the selection and modulation of sensory information. External attention selects locations in space, points in time, or modality-specific input. Such perceptual attention can also select features defined across any of these dimensions, or object representations that integrate over space, time, and modality. Internal attention refers to the selection, modulation, and maintenance of internally generated information, such as task rules, responses, long-term memory, or working memory. Working memory, in particular, lies closest to the intersection between external and internal attention. The taxonomy provides an organizing framework that recasts classic debates, raises new issues, and frames understanding of neural mechanisms.},
	number = {1},
	urldate = {2013-07-06},
	journal = {Annual Review of Psychology},
	author = {Chun, Marvin M. and Golomb, Julie D. and Turk-Browne, Nicholas B.},
	year = {2011},
	pmid = {19575619},
	keywords = {cognitive control, Perception, selection, consciousness, memory},
	pages = {73--101},
	file = {Full Text PDF:/Users/brownen1/Zotero/storage/6PIFDDH9/Chun et al. - 2011 - A Taxonomy of External and Internal Attention.pdf:application/pdf}
}

@article{Noudoost:2010,
	title = {Top-down control of visual attention},
	volume = {20},
	issn = {0959-4388},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2901796/},
	doi = {10.1016/j.conb.2010.02.003},
	abstract = {Top-down visual attention improves perception of selected stimuli and that improvement is reflected in the neural activity at many stages throughout the visual system. Recent studies of top-down attention have elaborated on the signatures of its effects within visual cortex and have begun identifying its causal basis. Evidence from these studies suggests that the correlates of spatial attention exhibited by neurons within the visual system originate from a distributed network of structures involved in the programming of saccadic eye movements. We summarize this evidence and discuss its relationship to the neural mechanisms of spatial working memory.},
	number = {2},
	urldate = {2013-10-30},
	journal = {Current opinion in neurobiology},
	author = {Noudoost, Behrad and Chang, Mindy H. and Steinmetz, Nicholas A. and Moore, Tirin},
	month = apr,
	year = {2010},
	pmid = {20303256},
	pmcid = {PMC2901796},
	keywords = {Animals, Attention, Executive function, Humans, Nerve Net, Neural Pathways, Neurons, Neurotransmitter Agents, Psychomotor Performance, Saccades, visual cortex, Visual Perception},
	pages = {183--190}
}

@article{Itti:2000,
	title = {A saliency-based search mechanism for overt and covert shifts of visual attention},
	volume = {40},
	issn = {0042-6989},
	url = {http://www.sciencedirect.com/science/article/pii/S0042698999001637},
	doi = {10.1016/S0042-6989(99)00163-7},
	abstract = {Most models of visual search, whether involving overt eye movements or covert shifts of attention, are based on the concept of a saliency map, that is, an explicit two-dimensional map that encodes the saliency or conspicuity of objects in the visual environment. Competition among neurons in this map gives rise to a single winning location that corresponds to the next attended target. Inhibiting this location automatically allows the system to attend to the next most salient location. We describe a detailed computer implementation of such a scheme, focusing on the problem of combining information across modalities, here orientation, intensity and color information, in a purely stimulus-driven manner. The model is applied to common psychophysical stimuli as well as to a very demanding visual search task. Its successful performance is used to address the extent to which the primate visual system carries out visual search via one or more such saliency maps and how this can be tested.},
	number = {10},
	urldate = {2018-05-17},
	journal = {Vision Research},
	author = {Itti, Laurent and Koch, Christof},
	month = jun,
	year = {2000},
	keywords = {Saliency, Vision systems, Visual attention},
	pages = {1489--1506},
	file = {ScienceDirect Full Text PDF:/Users/brownen1/Zotero/storage/PUM6IDZ5/Itti and Koch - 2000 - A saliency-based search mechanism for overt and co.pdf:application/pdf;ScienceDirect Snapshot:/Users/brownen1/Zotero/storage/BVQ7TDST/S0042698999001637.html:text/html}
}

@article{Most:2005,
	title = {What {You} {See} {Is} {What} {You} {Set}: {Sustained} {Inattentional} {Blindness} and the {Capture} of {Awareness}},
	volume = {112},
	issn = {1939-1471(Electronic),0033-295X(Print)},
	shorttitle = {What {You} {See} {Is} {What} {You} {Set}},
	doi = {10.1037/0033-295X.112.1.217},
	abstract = {This article reports a theoretical and experimental attempt to relate and contrast 2 traditionally separate research programs: inattentional blindness and attention capture. Inattentional blindness refers to failures to notice unexpected objects and events when attention is otherwise engaged. Attention capture research has traditionally used implicit indices (e.g., response times) to investigate automatic shifts of attention. Because attention capture usually measures performance whereas inattentional blindness measures awareness, the 2 fields have existed side by side with no shared theoretical framework. Here, the authors propose a theoretical unification, adapting several important effects from the attention capture literature to the context of sustained inattentional blindness. Although some stimulus properties can influence noticing of unexpected objects, the most influential factor affecting noticing is a person's own attentional goals. The authors conclude that many--but not all--aspects of attention capture apply to inattentional blindness but that these 2 classes of phenomena remain importantly distinct. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {1},
	journal = {Psychological Review},
	author = {Most, Steven B. and Scholl, Brian J. and Clifford, Erin R. and Simons, Daniel J.},
	year = {2005},
	keywords = {Attention, Awareness},
	pages = {217--242},
	file = {Snapshot:/Users/brownen1/Zotero/storage/T3L2I3W9/2004-22409-009.html:text/html}
}

@article{Turk-Browne:2005,
	title = {The automaticity of visual statistical learning},
	volume = {134},
	issn = {1939-2222(Electronic),0096-3445(Print)},
	doi = {10.1037/0096-3445.134.4.552},
	abstract = {The visual environment contains massive amounts of information involving the relations between objects in space and time, and recent studies of visual statistical learning (VSL) have suggested that this information can be automatically extracted by the visual system. The experiments reported in this article explore the automaticity of VSL in several ways, using both explicit familiarity and implicit response-time measures. The results demonstrate that (a) the input to VSL is gated by selective attention, (b) VSL is nevertheless an implicit process because it operates during a cover task and without awareness of the underlying statistical patterns, and (c) VSL constructs abstracted representations that are then invariant to changes in extraneous surface features. These results fuel the conclusion that VSL both is and is not automatic: It requires attention to select the relevant population of stimuli, but the resulting learning then occurs without intent or awareness. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {4},
	journal = {Journal of Experimental Psychology: General},
	author = {Turk-Browne, Nicholas B. and Jungé, Justin A. and Scholl, Brian J.},
	year = {2005},
	keywords = {Reaction Time, Visual Perception, Automatism, Implicit Learning},
	pages = {552--564},
	file = {Snapshot:/Users/brownen1/Zotero/storage/ED7I3VP3/2005-14939-007.html:text/html}
}

@article{Aly:2016,
	title = {Attention promotes episodic encoding by stabilizing hippocampal representations},
	volume = {113},
	copyright = {©  . http://www.pnas.org/preview\_site/misc/userlicense.xhtml},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/content/113/4/E420},
	doi = {10.1073/pnas.1518931113},
	abstract = {Attention influences what is later remembered, but little is known about how this occurs in the brain. We hypothesized that behavioral goals modulate the attentional state of the hippocampus to prioritize goal-relevant aspects of experience for encoding. Participants viewed rooms with paintings, attending to room layouts or painting styles on different trials during high-resolution functional MRI. We identified template activity patterns in each hippocampal subfield that corresponded to the attentional state induced by each task. Participants then incidentally encoded new rooms with art while attending to the layout or painting style, and memory was subsequently tested. We found that when task-relevant information was better remembered, the hippocampus was more likely to have been in the correct attentional state during encoding. This effect was specific to the hippocampus, and not found in medial temporal lobe cortex, category-selective areas of the visual system, or elsewhere in the brain. These findings provide mechanistic insight into how attention transforms percepts into memories.},
	language = {en},
	number = {4},
	urldate = {2018-05-23},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Aly, Mariam and Turk-Browne, Nicholas B.},
	month = jan,
	year = {2016},
	pmid = {26755611},
	keywords = {long-term memory, hippocampal subfields, medial temporal lobe, representational stability, selective attention},
	pages = {E420--E429},
	file = {Full Text PDF:/Users/brownen1/Zotero/storage/VE8F42HS/Aly and Turk-Browne - 2016 - Attention promotes episodic encoding by stabilizin.pdf:application/pdf;Snapshot:/Users/brownen1/Zotero/storage/WVLZL82Z/E420.html:text/html}
}

@incollection{Yantis:2000,
	title = {Goal-directed and stimulus-driven determinants of attentional control},
	isbn = {978-0-262-13367-8},
	abstract = {One of the most challenging problems facing cognitive psychology and cognitive neuroscience is to explain how mental processes are voluntarily controlled, allowing the computational resources of the brain to be selected flexibly and deployed to achieve changing goals. The eighteenth of the celebrated international symposia on Attention and Performance focused on this problem, seeking to banish or at least deconstruct the "homunculus": that conveniently intelligent, but opaque, agent still lurking within many theories, under the guise of a central executive or supervisory attentional system assumed to direct processes that are not "automatic." The thirty-two contributions discuss evidence from psychological experiments with healthy and brain-damaged subjects, functional imaging, electrophysiology, and computational modeling. Four sections focus on specific forms of control: of visual attention, of perception-action coupling, of task-switching and dual-task performance, and of multistep tasks. The other three sections extend the interdisciplinary approach, with chapters on the neural substrate of control, studies of control disorders, and computational simulations. The progress achieved in fractionating, localizing, and modeling control functions, and in understanding the interaction between stimulus-driven and voluntary control, takes research on control in the mind/brain to a new level of sophistication.},
	language = {en},
	booktitle = {Control of {Cognitive} {Processes}: {Attention} and {Performance} {XVIII}},
	publisher = {MIT Press},
	author = {Yantis, Steven},
	year = {2000},
	note = {Google-Books-ID: kO\_baYlSVbwC},
	keywords = {Psychology / Cognitive Psychology \& Cognition},
	pages = {73--103}
}

@article{Kastner:2000,
	title = {Mechanisms of {Visual} {Attention} in the {Human} {Cortex}},
	volume = {23},
	url = {https://doi.org/10.1146/annurev.neuro.23.1.315},
	doi = {10.1146/annurev.neuro.23.1.315},
	abstract = {A typical scene contains many different objects that, because of the limited processing capacity of the visual system, compete for neural representation. The competition among multiple objects in visual cortex can be biased by both bottom-up sensory-driven mechanisms and top-down influences, such as selective attention. Functional brain imaging studies reveal that, both in the absence and in the presence of visual stimulation, biasing signals due to selective attention can modulate neural activity in visual cortex in several ways. Although the competition among stimuli for representation is ultimately resolved within visual cortex, the source of top-down biasing signals derives from a network of areas in frontal and parietal cortex.},
	number = {1},
	urldate = {2018-05-23},
	journal = {Annual Review of Neuroscience},
	author = {Kastner, Sabine and Ungerleider, Leslie G.},
	year = {2000},
	pmid = {10845067},
	pages = {315--341}
}

@article{Turk-Browne:2013b,
	title = {Functional {Interactions} as {Big} {Data} in the {Human} {Brain}},
	volume = {342},
	copyright = {Copyright © 2013, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/342/6158/580},
	doi = {10.1126/science.1238409},
	abstract = {Noninvasive studies of human brain function hold great potential to unlock mysteries of the human mind. The complexity of data generated by such studies, however, has prompted various simplifying assumptions during analysis. Although this has enabled considerable progress, our current understanding is partly contingent upon these assumptions. An emerging approach embraces the complexity, accounting for the fact that neural representations are widely distributed, neural processes involve interactions between regions, interactions vary by cognitive state, and the space of interactions is massive. Because what you see depends on how you look, such unbiased approaches provide the greatest flexibility for discovery.},
	language = {en},
	number = {6158},
	urldate = {2016-08-05},
	journal = {Science},
	author = {Turk-Browne, Nicholas B.},
	month = nov,
	year = {2013},
	pmid = {24179218},
	pages = {580--584},
	file = {Full Text PDF:/Users/brownen1/Zotero/storage/RJ6BA9JF/Turk-Browne - 2013 - Functional Interactions as Big Data in the Human B.pdf:application/pdf;Snapshot:/Users/brownen1/Zotero/storage/KEUDC82S/580.html:text/html}
}



@article{Cowen:2014,
	title = {Neural portraits of perception: {Reconstructing} face images from evoked brain activity},
	volume = {94},
	issn = {1053-8119},
	shorttitle = {Neural portraits of perception},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811914001633},
	doi = {10.1016/j.neuroimage.2014.03.018},
	abstract = {Recent neuroimaging advances have allowed visual experience to be reconstructed from patterns of brain activity. While neural reconstructions have ranged in complexity, they have relied almost exclusively on retinotopic mappings between visual input and activity in early visual cortex. However, subjective perceptual information is tied more closely to higher-level cortical regions that have not yet been used as the primary basis for neural reconstructions. Furthermore, no reconstruction studies to date have reported reconstructions of face images, which activate a highly distributed cortical network. Thus, we investigated (a) whether individual face images could be accurately reconstructed from distributed patterns of neural activity, and (b) whether this could be achieved even when excluding activity within occipital cortex. Our approach involved four steps. (1) Principal component analysis (PCA) was used to identify components that efficiently represented a set of training faces. (2) The identified components were then mapped, using a machine learning algorithm, to fMRI activity collected during viewing of the training faces. (3) Based on activity elicited by a new set of test faces, the algorithm predicted associated component scores. (4) Finally, these scores were transformed into reconstructed images. Using both objective and subjective validation measures, we show that our methods yield strikingly accurate neural reconstructions of faces even when excluding occipital cortex. This methodology not only represents a novel and promising approach for investigating face perception, but also suggests avenues for reconstructing ‘offline’ visual experiences—including dreams, memories, and imagination—which are chiefly represented in higher-level cortical areas.},
	urldate = {2018-05-25},
	journal = {NeuroImage},
	author = {Cowen, Alan S. and Chun, Marvin M. and Kuhl, Brice A.},
	month = jul,
	year = {2014},
	pages = {12--22},
	file = {ScienceDirect Snapshot:/Users/brownen1/Zotero/storage/AAG32K9M/S1053811914001633.html:text/html}
}

@article{Sprague:2016,
	title = {Restoring {Latent} {Visual} {Working} {Memory} {Representations} in {Human} {Cortex}},
	volume = {91},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S089662731630352X},
	doi = {10.1016/j.neuron.2016.07.006},
	abstract = {Summary
Working memory (WM) enables the storage and manipulation of limited amounts of information over short periods. Prominent models posit that increasing the number of remembered items decreases the spiking activity dedicated to each item via mutual inhibition, which irreparably degrades the fidelity of each item’s representation. We tested these models by determining if degraded memory representations could be recovered following a post-cue indicating which of several items in spatial WM would be recalled. Using an fMRI-based image reconstruction technique, we identified impaired behavioral performance and degraded mnemonic representations with elevated memory load. However, in several cortical regions, degraded mnemonic representations recovered substantially following a post-cue, and this recovery tracked behavioral performance. These results challenge pure spike-based models of WM and suggest that remembered items are additionally encoded within latent or hidden neural codes that can help reinvigorate active WM representations.},
	number = {3},
	urldate = {2018-05-25},
	journal = {Neuron},
	author = {Sprague, Thomas C. and Ester, Edward F. and Serences, John T.},
	month = aug,
	year = {2016},
	pages = {694--707},
	file = {ScienceDirect Full Text PDF:/Users/brownen1/Zotero/storage/2BU6AA6U/Sprague et al. - 2016 - Restoring Latent Visual Working Memory Representat.pdf:application/pdf;ScienceDirect Snapshot:/Users/brownen1/Zotero/storage/52YXU7U3/S089662731630352X.html:text/html}
}

@article{Naselaris:2009,
	title = {Bayesian reconstruction of natural images from human brain activity},
	volume = {63},
	issn = {0896-6273},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5553889/},
	doi = {10.1016/j.neuron.2009.09.006},
	abstract = {Recent studies have used fMRI signals from early visual areas to reconstruct simple geometric patterns. Here, we demonstrate a new Bayesian decoder that uses fMRI signals from early and anterior visual areas to reconstruct complex natural images. Our decoder combines three elements: a structural encoding model that characterizes responses in early visual areas; a semantic encoding model that characterizes responses in anterior visual areas; and prior information about the structure and semantic content of natural images. By combining all these elements, the decoder produces reconstructions that accurately reflect both the spatial structure and semantic category of the objects contained in the observed natural image. Our results show that prior information has a substantial effect on the quality of natural image reconstructions. We also demonstrate that much of the variance in the responses of anterior visual areas to complex natural images is explained by the semantic category of the image alone.},
	number = {6},
	urldate = {2018-05-25},
	journal = {Neuron},
	author = {Naselaris, Thomas and Prenger, Ryan J. and Kay, Kendrick N. and Oliver, Michael and Gallant, Jack L.},
	month = sep,
	year = {2009},
	pmid = {19778517},
	pmcid = {PMC5553889},
	pages = {902--915},
	file = {PubMed Central Full Text PDF:/Users/brownen1/Zotero/storage/FYCF28DH/Naselaris et al. - 2009 - Bayesian reconstruction of natural images from hum.pdf:application/pdf}
}

@article{Brouwer:2009,
	title = {Decoding and reconstructing color from responses in human visual cortex},
	volume = {29},
	issn = {0270-6474},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2799419/},
	doi = {10.1523/JNEUROSCI.3577-09.2009},
	abstract = {How is color represented by spatially distributed patterns of activity in visual cortex? Functional magnetic resonance imaging (fMRI) responses to several stimulus colors were analyzed with multivariate techniques: conventional pattern classification, a forward model of idealized color tuning, and principal component analysis (PCA). Stimulus color was accurately decoded from activity in V1, V2, V3, V4, VO1 but not LO1, LO2, V3A/B or MT+. The conventional classifier and forward model yielded similar accuracies, but the forward model (unlike the classifier) also reliably reconstructed novel stimulus colors not used to train (specify parameters of) the model. The mean responses, averaged across voxels in each visual area, were not reliably distinguishable for the different stimulus colors. Hence, each stimulus color was associated with a unique spatially distributed pattern of activity, presumably reflecting the color-selectivity of cortical neurons. In a complementary PCA analysis, a color space was derived from the covariation, across voxels, in the responses to different colors. In V4 and VO1, the first two principal component scores (main source of variation) of the responses revealed a progression through perceptual color space, with perceptually similar colors evoking the most similar responses. This was not the case for any of the other visual cortical areas, including V1, even though decoding was most accurate in V1. This dissociation implies a transformation from the color representation in V1 to reflect perceptual color space in V4 and VO1.},
	number = {44},
	urldate = {2018-05-25},
	journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
	author = {Brouwer, Gijs Joost and Heeger, David J.},
	month = nov,
	year = {2009},
	pmid = {19890009},
	pmcid = {PMC2799419},
	pages = {13992--14003},
	file = {PubMed Central Full Text PDF:/Users/brownen1/Zotero/storage/J5VAUNMZ/Brouwer and Heeger - 2009 - Decoding and reconstructing color from responses i.pdf:application/pdf}
}

@inproceedings{YuLL11,
  author    = {Kai Yu and
               Yuanqing Lin and
               John D. Lafferty},
  title     = {Learning image representations from the pixel level via hierarchical
               sparse coding},
  booktitle = {The 24th {IEEE} Conference on Computer Vision and Pattern Recognition,
               {CVPR} 2011, Colorado Springs, CO, USA, 20-25 June 2011},
  pages     = {1713--1720},
  year      = {2011},
}

@inproceedings{WangYYLHG10,
  author    = {Jinjun Wang and
               Jianchao Yang and
               Kai Yu and
               Fengjun Lv and
               Thomas S. Huang and
               Yihong Gong},
  title     = {Locality-constrained Linear Coding for image classification},
  booktitle = {The Twenty-Third {IEEE} Conference on Computer Vision and Pattern
               Recognition, {CVPR} 2010, San Francisco, CA, USA, 13-18 June 2010},
  pages     = {3360--3367},
  year      = {2010},
}

@article{ChangJZBG11,
  author    = {Lo{-}Bin Chang and
               Ya Jin and
               Wei Zhang and
               Eran Borenstein and
               Stuart Geman},
  title     = {Context, Computation, and Optimal {ROC} Performance in Hierarchical
               Models},
  journal   = {International Journal of Computer Vision},
  volume    = {93},
  number    = {2},
  pages     = {117--140},
  year      = {2011},
}

@inproceedings{JinG06,
  author    = {Ya Jin and
               Stuart Geman},
  title     = {Context and Hierarchy in a Probabilistic Image Model},
  booktitle = {2006 {IEEE} Computer Society Conference on Computer Vision and Pattern
               Recognition {(CVPR} 2006), 17-22 June 2006, New York, NY, {USA}},
  pages     = {2145--2152},
  year      = {2006},
}

@article{HatsopoulosGAB03,
  author    = {N. Hatsopoulos and
               Stuart Geman and
               Asohan Amarasingham and
               Elie Bienenstock},
  title     = {At what time scale does the nervous system operate?},
  journal   = {Neurocomputing},
  volume    = {52-54},
  pages     = {25--29},
  year      = {2003},
}


@book{horowitz09,
  author = {Joel L. Horowitz},
  title = {Semiparametric and nonparametric methods in econometrics},
  publisher = {Springer},
  year = {2009},
}

@article{horowitz96,
  author = {Joel L. Horowitz and Wolfgang Hardle},
  title = {Direct semiparametric estimation of single-index models with discrete covariates},
  journal = {Journal of the American Statistical Association},
  volume = {91},
  number = {436},
  pages = {1632--1640},
  year = {1996},
}

@article{ichimura93,
  author = {Hidehiko Ichimura},
  title = {Semiparametric least squares (sls) and weighted sls estimation of single-index models},
  journal = {Journal of Econometrics},
  volume = {58},
  number = {1},
  pages = {71--120},
  year = {1993},
}


@inproceedings{kakade11,
  author = {Sham M Kakade and Varun Kanade and Ohad Shamir and Adam Kalai},
  title = {Efficient learning of generalized linear and single index models with isotonic regression},
  booktitle = {In Advances in Neural Information Processing Systems},
  pages = {927--935},
  year = {2011},
}

@article{negahban12,
  author = {Sahand N. Negahban and Pradeep Ravikumar and Martin J. Wainwright and Bin Yu},
  title = {A unified framework for high dimensional analysis of {M}-estimators with 
   decomposable regularizers},
  journal = {Statistical Science},
  volume = {27},
  number = {4},
  pages = {538--557},
  year = {2012},
}


@article{chen17,
  author = {J. Chen and Y.C. Leong and C.J. Honey and C.H. Yong and K.A. Norman and U. Hasson},
  year = {2017},
  title = {Shared memories reveal shared structure in neural activity across individuals},
  journal = {Nature Neuroscience},
}

@article{baldassano17,
  author = {C. Baldassano and J. Chen and A. Zadbood and J.W. Pillow and U. Hasson and K.A. Norman},
  year = {2017},
  title = {Discovering event structure in continuous narrative perception and memory},
  journal = {Neuron},
}
